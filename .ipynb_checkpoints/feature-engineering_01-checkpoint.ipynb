{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 717,
   "id": "ffca79dc-85b7-406e-ba2d-a68b4fa0aae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libararies\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 718,
   "id": "97c30944-0a52-4f23-9141-d72bb51dad0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     PassengerId HomePlanet CryoSleep     Cabin    Destination   Age    VIP  \\\n",
      "0        0001_01     Europa     False     B/0/P    TRAPPIST-1e  39.0  False   \n",
      "1        0002_01      Earth     False     F/0/S    TRAPPIST-1e  24.0  False   \n",
      "2        0003_01     Europa     False     A/0/S    TRAPPIST-1e  58.0   True   \n",
      "3        0003_02     Europa     False     A/0/S    TRAPPIST-1e  33.0  False   \n",
      "4        0004_01      Earth     False     F/1/S    TRAPPIST-1e  16.0  False   \n",
      "...          ...        ...       ...       ...            ...   ...    ...   \n",
      "8688     9276_01     Europa     False    A/98/P    55 Cancri e  41.0   True   \n",
      "8689     9278_01      Earth      True  G/1499/S  PSO J318.5-22  18.0  False   \n",
      "8690     9279_01      Earth     False  G/1500/S    TRAPPIST-1e  26.0  False   \n",
      "8691     9280_01     Europa     False   E/608/S    55 Cancri e  32.0  False   \n",
      "8692     9280_02     Europa     False   E/608/S    TRAPPIST-1e  44.0  False   \n",
      "\n",
      "      RoomService  FoodCourt  ShoppingMall     Spa  VRDeck               Name  \\\n",
      "0             0.0        0.0           0.0     0.0     0.0    Maham Ofracculy   \n",
      "1           109.0        9.0          25.0   549.0    44.0       Juanna Vines   \n",
      "2            43.0     3576.0           0.0  6715.0    49.0      Altark Susent   \n",
      "3             0.0     1283.0         371.0  3329.0   193.0       Solam Susent   \n",
      "4           303.0       70.0         151.0   565.0     2.0  Willy Santantines   \n",
      "...           ...        ...           ...     ...     ...                ...   \n",
      "8688          0.0     6819.0           0.0  1643.0    74.0  Gravior Noxnuther   \n",
      "8689          0.0        0.0           0.0     0.0     0.0    Kurta Mondalley   \n",
      "8690          0.0        0.0        1872.0     1.0     0.0       Fayey Connon   \n",
      "8691          0.0     1049.0           0.0   353.0  3235.0   Celeon Hontichre   \n",
      "8692        126.0     4688.0           0.0     0.0    12.0   Propsh Hontichre   \n",
      "\n",
      "      Transported  \n",
      "0           False  \n",
      "1            True  \n",
      "2           False  \n",
      "3           False  \n",
      "4            True  \n",
      "...           ...  \n",
      "8688        False  \n",
      "8689        False  \n",
      "8690         True  \n",
      "8691        False  \n",
      "8692         True  \n",
      "\n",
      "[8693 rows x 14 columns]\n",
      "     PassengerId HomePlanet CryoSleep     Cabin    Destination   Age    VIP  \\\n",
      "0        0013_01      Earth      True     G/3/S    TRAPPIST-1e  27.0  False   \n",
      "1        0018_01      Earth     False     F/4/S    TRAPPIST-1e  19.0  False   \n",
      "2        0019_01     Europa      True     C/0/S    55 Cancri e  31.0  False   \n",
      "3        0021_01     Europa     False     C/1/S    TRAPPIST-1e  38.0  False   \n",
      "4        0023_01      Earth     False     F/5/S    TRAPPIST-1e  20.0  False   \n",
      "...          ...        ...       ...       ...            ...   ...    ...   \n",
      "4272     9266_02      Earth      True  G/1496/S    TRAPPIST-1e  34.0  False   \n",
      "4273     9269_01      Earth     False       NaN    TRAPPIST-1e  42.0  False   \n",
      "4274     9271_01       Mars      True   D/296/P    55 Cancri e   NaN  False   \n",
      "4275     9273_01     Europa     False   D/297/P            NaN   NaN  False   \n",
      "4276     9277_01      Earth      True  G/1498/S  PSO J318.5-22  43.0  False   \n",
      "\n",
      "      RoomService  FoodCourt  ShoppingMall     Spa  VRDeck              Name  \n",
      "0             0.0        0.0           0.0     0.0     0.0   Nelly Carsoning  \n",
      "1             0.0        9.0           0.0  2823.0     0.0    Lerome Peckers  \n",
      "2             0.0        0.0           0.0     0.0     0.0   Sabih Unhearfus  \n",
      "3             0.0     6652.0           0.0   181.0   585.0  Meratz Caltilter  \n",
      "4            10.0        0.0         635.0     0.0     0.0   Brence Harperez  \n",
      "...           ...        ...           ...     ...     ...               ...  \n",
      "4272          0.0        0.0           0.0     0.0     0.0       Jeron Peter  \n",
      "4273          0.0      847.0          17.0    10.0   144.0     Matty Scheron  \n",
      "4274          0.0        0.0           0.0     0.0     0.0       Jayrin Pore  \n",
      "4275          0.0     2680.0           0.0     0.0   523.0    Kitakan Conale  \n",
      "4276          0.0        0.0           0.0     0.0     0.0  Lilace Leonzaley  \n",
      "\n",
      "[4277 rows x 13 columns]\n"
     ]
    }
   ],
   "source": [
    "# import data\n",
    "work_dir = Path.cwd()\n",
    "train_df = pd.read_csv(work_dir/\"kaggle-data\"/\"train.csv\")\n",
    "print(train_df)\n",
    "test_df = pd.read_csv(work_dir/\"kaggle-data\"/\"test.csv\")\n",
    "print(test_df)\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 719,
   "id": "e86f8537-9b56-4484-a010-8d40558aa2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_cabin_num_to_bins(num):\n",
    "    try:\n",
    "        num = int(num)\n",
    "    except ValueError:\n",
    "        return pd.NA\n",
    "    if num <= 300:\n",
    "        return 1\n",
    "    elif num <= 600:\n",
    "        return 2\n",
    "    elif num <= 900:\n",
    "        return 3\n",
    "    elif num <= 1200:\n",
    "        return 4\n",
    "    elif num <= 1500:\n",
    "        return 5\n",
    "    else:\n",
    "        return 6\n",
    "\n",
    "def process_data(df, file_name):\n",
    "    # splitting passenger id and cabin information into multiple columns, removing not needed columns\n",
    "    df[\"PassengerGroup\"] = df[\"PassengerId\"].str.split(\"_\").str[0]\n",
    "    df[\"GroupSize\"] = df.groupby(\"PassengerGroup\")[\"PassengerGroup\"].transform(\"count\")\n",
    "\n",
    "    df[\"CabinDeck\"] = df[\"Cabin\"].str.split(\"/\").str[0]\n",
    "    df[\"CabinNum\"] = df[\"Cabin\"].str.split(\"/\").str[1]\n",
    "    df[\"CabinSide\"] = df[\"Cabin\"].str.split(\"/\").str[2]\n",
    "\n",
    "    df.drop([\"PassengerId\", \"Cabin\", \"Name\", \"PassengerGroup\"], axis=1, inplace=True)\n",
    "\n",
    "    # gathering CabinNum into bins\n",
    "    df[\"CabinNumBin\"] = df[\"CabinNum\"].map(map_cabin_num_to_bins)\n",
    "    df.drop(\"CabinNum\", axis=1, inplace=True)\n",
    "\n",
    "    # one hot encoding \"HomePlanet\", \"Destination\", \"CabinDeck\", \"CabinSide\" and \"CabinNumBin\"\n",
    "    columns_to_encode = [\"HomePlanet\", \"Destination\", \"CabinDeck\", \"CabinSide\", \"CabinNumBin\"]\n",
    "    encoder = OneHotEncoder(sparse_output=False)\n",
    "    encoded_array = encoder.fit_transform(df[columns_to_encode])\n",
    "    encoded_df = pd.DataFrame(encoded_array, columns=encoder.get_feature_names_out(columns_to_encode))\n",
    "    df.drop(columns_to_encode, axis=1, inplace=True)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    df = pd.concat([df, encoded_df], axis=1)\n",
    "\n",
    "    # changing columns CryoSleep and VIP to bool type\n",
    "    train_df[[\"CryoSleep\", \"VIP\"]] = train_df[[\"CryoSleep\", \"VIP\"]].astype(bool)\n",
    "\n",
    "    # scaling columns containing numerical values\n",
    "    columns_to_scale = [\"Age\", \"RoomService\", \"FoodCourt\", \"ShoppingMall\", \"Spa\", \"VRDeck\", \"GroupSize\"]\n",
    "    scaler = MinMaxScaler()\n",
    "    df[columns_to_scale] = scaler.fit_transform(df[columns_to_scale])\n",
    "\n",
    "    df.to_csv(file_name + \".csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 720,
   "id": "7a59db80-f127-412e-919f-6171650958a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first dataset - all rows containing NA values removed\n",
    "# train data\n",
    "dataset_01_train = train_df.dropna().copy()\n",
    "process_data(dataset_01_train, \"dataset_01_train\")\n",
    "# test data\n",
    "dataset_01_test = test_df.dropna().copy()\n",
    "process_data(dataset_01_test, \"dataset_01_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 721,
   "id": "2e71a56c-f730-4b8a-9b0e-2c528da62f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# second dataset - removing NA values from the CryoSleep column, imputing the rest\n",
    "#train data\n",
    "dataset_02_train = train_df.dropna(subset=\"CryoSleep\").copy()\n",
    "# missing categorical data with be imputed in a way that conserves proportions\n",
    "dataset_02_train[\"HomePlanet\"] = dataset_02_train[\"HomePlanet\"].apply(lambda x: random.choice(dataset_02_train[\"HomePlanet\"].dropna().tolist()) if pd.isna(x) else x)\n",
    "dataset_02_train[\"Cabin\"] = dataset_02_train[\"Cabin\"].apply(lambda x: random.choice(dataset_02_train[\"Cabin\"].dropna().tolist()) if pd.isna(x) else x)\n",
    "dataset_02_train[\"Destination\"] = dataset_02_train[\"Destination\"].apply(lambda x: random.choice(dataset_02_train[\"Destination\"].dropna().tolist()) if pd.isna(x) else x)\n",
    "dataset_02_train[\"VIP\"] = dataset_02_train[\"VIP\"].apply(lambda x: random.choice(dataset_02_train[\"VIP\"].dropna().tolist()) if pd.isna(x) else x)\n",
    "\n",
    "# missing values from the numerical columns imputed with the median\n",
    "dataset_02_train[\"Age\"] = dataset_02_train[\"Age\"].fillna(dataset_02[\"Age\"].median())\n",
    "dataset_02_train[\"RoomService\"] = dataset_02_train[\"RoomService\"].fillna(dataset_02_train[\"RoomService\"].median())\n",
    "dataset_02_train[\"FoodCourt\"] = dataset_02_train[\"FoodCourt\"].fillna(dataset_02_train[\"FoodCourt\"].median())\n",
    "dataset_02_train[\"ShoppingMall\"] = dataset_02_train[\"ShoppingMall\"].fillna(dataset_02_train[\"ShoppingMall\"].median())\n",
    "dataset_02_train[\"Spa\"] = dataset_02_train[\"Spa\"].fillna(dataset_02_train[\"Spa\"].median())\n",
    "dataset_02_train[\"VRDeck\"] = dataset_02_train[\"VRDeck\"].fillna(dataset_02_train[\"VRDeck\"].median())\n",
    "process_data(dataset_02_train, \"dataset_02_train\")\n",
    "\n",
    "#test data\n",
    "dataset_02_test = test_df.dropna(subset=\"CryoSleep\").copy()\n",
    "# missing categorical data with be imputed in a way that conserves proportions\n",
    "dataset_02_test[\"HomePlanet\"] = dataset_02_test[\"HomePlanet\"].apply(lambda x: random.choice(dataset_02_test[\"HomePlanet\"].dropna().tolist()) if pd.isna(x) else x)\n",
    "dataset_02_test[\"Cabin\"] = dataset_02_test[\"Cabin\"].apply(lambda x: random.choice(dataset_02_test[\"Cabin\"].dropna().tolist()) if pd.isna(x) else x)\n",
    "dataset_02_test[\"Destination\"] = dataset_02_test[\"Destination\"].apply(lambda x: random.choice(dataset_02_test[\"Destination\"].dropna().tolist()) if pd.isna(x) else x)\n",
    "dataset_02_test[\"VIP\"] = dataset_02_test[\"VIP\"].apply(lambda x: random.choice(dataset_02_test[\"VIP\"].dropna().tolist()) if pd.isna(x) else x)\n",
    "\n",
    "# missing values from the numerical columns imputed with the median\n",
    "dataset_02_test[\"Age\"] = dataset_02_test[\"Age\"].fillna(dataset_02[\"Age\"].median())\n",
    "dataset_02_test[\"RoomService\"] = dataset_02_test[\"RoomService\"].fillna(dataset_02_test[\"RoomService\"].median())\n",
    "dataset_02_test[\"FoodCourt\"] = dataset_02_test[\"FoodCourt\"].fillna(dataset_02_test[\"FoodCourt\"].median())\n",
    "dataset_02_test[\"ShoppingMall\"] = dataset_02_test[\"ShoppingMall\"].fillna(dataset_02_test[\"ShoppingMall\"].median())\n",
    "dataset_02_test[\"Spa\"] = dataset_02_test[\"Spa\"].fillna(dataset_02_test[\"Spa\"].median())\n",
    "dataset_02_test[\"VRDeck\"] = dataset_02_test[\"VRDeck\"].fillna(dataset_02_test[\"VRDeck\"].median())\n",
    "process_data(dataset_02_test, \"dataset_02_test\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
